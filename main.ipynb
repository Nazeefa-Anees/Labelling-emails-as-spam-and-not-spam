{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#As the first step, Data preprocessing is done, which includes loading the dataset,cleaning the dataset and then splitting it into training and testing sets with a percentage of 80% to 20%. Finally the data is scaled to a common scale using minmax scaler which ranges the data from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#load the dataset and include headers\n",
    "headers = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', \n",
    "           'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
    "           'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses',\n",
    "           'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "           'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp',\n",
    "           'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs',\n",
    "           'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
    "           'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "           'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
    "           'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(',\n",
    "           'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average',\n",
    "           'capital_run_length_longest', 'capital_run_length_total', 'spam']\n",
    "\n",
    "dataset=pd.read_csv('dataset/spambase.data',header=None, names=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "spam                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. EMPTY VALUES\n",
    "\n",
    "#checking if there are empty values\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "#'There are no missing values'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates : 391\n",
      "number of duplicates (after): 0\n"
     ]
    }
   ],
   "source": [
    "#2.DUPLICATES\n",
    "\n",
    "#checking for duplicate values\n",
    "duplicate=dataset.duplicated()\n",
    "num_duplicates = duplicate.sum()\n",
    "print('number of duplicates :', num_duplicates)\n",
    "#removing duplicate values\n",
    "dataset=dataset.drop_duplicates()\n",
    "\n",
    "\n",
    "duplicate=dataset.duplicated()\n",
    "num_duplicates = duplicate.sum()\n",
    "print('number of duplicates (after):',num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE DATASET INTO TRAINING AND TESTING\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data to improve performance\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_= scaler.fit_transform(X_train)\n",
    "X_test_=scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN model is trained. first the best hyperparameters are taken using gridsearchCv and then those selected hyperparameters are instantiated and the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
      "Best accuracy: 0.9094426391418027\n"
     ]
    }
   ],
   "source": [
    "##getting the best hyperparameters\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid to get the best hyperparameters\n",
    "param_grid = {'n_neighbors': np.arange(1, 20),'weights': ['uniform', 'distance'],'p': [1, 2]}\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_, y_train)\n",
    "\n",
    "# Print the best hyperparameters and accuracy score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121140142517815\n",
      "Precision: 0.9411764705882353\n",
      "Recall: 0.8467966573816156\n",
      "F1 score: 0.8914956011730205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Instantiate the KNN model with the selected hyperparameters\n",
    "knn_model = KNeighborsClassifier(n_neighbors=6, weights='distance', p=1)\n",
    "\n",
    "# Train the KNN model on the training set\n",
    "knn_model.fit(X_train_, y_train)\n",
    "\n",
    "\n",
    "y_pred = knn_model.predict(X_test_)\n",
    "\n",
    "# Evaluate the performance of the KNN model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       483\n",
      "           1       0.94      0.85      0.89       359\n",
      "\n",
      "    accuracy                           0.91       842\n",
      "   macro avg       0.92      0.90      0.91       842\n",
      "weighted avg       0.91      0.91      0.91       842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generating the classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[464  19]\n",
      " [ 55 304]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision tree model is trained. First the best hyperparameters are taken using gridsearchCv and then those selected hyperparameters are instantiated and the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "##getting the best hyperparameters\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# instantiate the decision tree model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6389548693586699\n",
      "Precision: 0.9365079365079365\n",
      "Recall: 0.16434540389972144\n",
      "F1 score: 0.2796208530805687\n",
      "Training accuracy: 0.9673396674584323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\ML\\cw\\Nazeefa_20210076_ML-CW\\venv\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "dt = grid_search.best_estimator_\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels of the testing set\n",
    "predictions_test = dt.predict(X_test_)\n",
    "\n",
    "# evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, predictions_test)\n",
    "precision = precision_score(y_test, predictions_test)\n",
    "recall = recall_score(y_test, predictions_test)\n",
    "f1 = f1_score(y_test, predictions_test)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "train_accuracy = dt.score(X_train, y_train)\n",
    "print(\"Training accuracy:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       483\n",
      "           1       0.94      0.85      0.89       359\n",
      "\n",
      "    accuracy                           0.91       842\n",
      "   macro avg       0.92      0.90      0.91       842\n",
      "weighted avg       0.91      0.91      0.91       842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generating the classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[464  19]\n",
      " [ 55 304]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e898a3dc9dbe88d7db2bdc61dbe6e1bb0fb51b4d36496851c235b2fcda8b784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
